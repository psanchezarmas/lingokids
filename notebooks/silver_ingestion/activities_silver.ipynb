{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aedfb615-5fdf-4a2e-8870-fb9463478960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " Bronze → Silver ETL (Incremental with Merge)\n",
    "\n",
    "Loads activities from Bronze to Silver using config and prevents duplicates via merge on `activity_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc26cb0b-3cdc-4cae-948d-532cf7546098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import size, from_json, size, current_timestamp\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0da7a056-f950-43dc-a419-54aa5a1ab77a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config_path = \"/Workspace/Users/pablo.sanchez.armas@gmail.com/lingokids/configs/silver/activities.yaml\"\n",
    "\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "source_cfg = config[\"source\"]\n",
    "target_cfg = config[\"target\"]\n",
    "load_cfg = config[\"load\"]\n",
    "\n",
    "bronze_table = f\"{source_cfg['catalog']}.{source_cfg['schema']}.{source_cfg['table']}\"\n",
    "silver_table = f\"{target_cfg['catalog']}.{target_cfg['schema']}.{target_cfg['table']}\"\n",
    "\n",
    "merge_key = load_cfg.get(\"merge_key\")\n",
    "if not merge_key:\n",
    "    raise ValueError(\"merge_key must be defined in the config file\")\n",
    "\n",
    "print(f\"Source: {bronze_table}\")\n",
    "print(f\"Target: {silver_table}\")\n",
    "print(f\"Merge Key: {merge_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddbe35f4-291f-421c-b28b-0c9e7d0211e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read from bronze\n",
    "df_bronze = spark.read.table(bronze_table)\n",
    "\n",
    "# Add processing timestamp\n",
    "df_bronze = df_bronze.withColumn(\"updated_at\", current_timestamp())\n",
    "\n",
    "# Create Silver table if it doesn't exist\n",
    "if not spark.catalog.tableExists(silver_table):\n",
    "    print(f\"Silver table {silver_table} does not exist — creating it.\")\n",
    "    (\n",
    "        df_bronze.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .saveAsTable(silver_table)\n",
    "    )\n",
    "\n",
    "# Prepare Delta table for merge\n",
    "silver_delta = DeltaTable.forName(spark, silver_table)\n",
    "\n",
    "# Merge condition (based on merge_key from config)\n",
    "merge_condition = f\"t.{merge_key} = s.{merge_key}\"\n",
    "\n",
    "# Perform the upsert:\n",
    "(\n",
    "    silver_delta.alias(\"t\")\n",
    "    .merge(\n",
    "        df_bronze.alias(\"s\"),\n",
    "        merge_condition\n",
    "    )\n",
    "    # Insert only new activities\n",
    "    .whenNotMatchedInsertAll()\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "print(\"✅ Merge completed: new activites added.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "activities_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
