{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11034e07-bcdc-4d0c-91ac-9e3310b1fc76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import yaml\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Get current workspace context from Databricks notebook\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "ctx = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "\n",
    "# ✅ Auto-detect host (workspace URL)\n",
    "host = ctx.apiUrl().get().replace(\"https://\", \"\").split(\"/\")[0]\n",
    "\n",
    "# ✅ Get personal access token of the current user\n",
    "token = ctx.apiToken().get()\n",
    "\n",
    "# ✅ Load config from YAML\n",
    "with open(\"setup.yaml\", \"r\") as f: \n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "catalog_config = config['catalog']\n",
    "\n",
    "# Load medallion schemas from YAML\n",
    "medallion_schemas = config.get(\"medallion_schemas\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0d542c5-6338-44fd-9db9-7926eb6a7d36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_or_update_catalog(name, comment, properties):\n",
    "    # Drop and create catalog\n",
    "    spark.sql(f\"DROP CATALOG IF EXISTS {name} CASCADE\")\n",
    "    spark.sql(f\"CREATE CATALOG {name} COMMENT '{comment}'\")\n",
    "\n",
    "    # REST API endpoint\n",
    "    api_url = f\"https://{host}/api/2.1/unity-catalog/catalogs/{name}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # Request payload\n",
    "    payload = {\"comment\": comment, \"properties\": properties}\n",
    "\n",
    "    # Send PATCH request\n",
    "    response = requests.patch(api_url, headers=headers, data=json.dumps(payload))\n",
    "    print(f\"Status code: {response.status_code}\")\n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9405ab5f-1f7c-4af7-b2a7-389f35249873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_medallion_schemas(catalog_name, schemas):\n",
    "    \"\"\"\n",
    "    Creates Bronze, Silver, and Gold schemas in the given catalog\n",
    "    using definitions from YAML.\n",
    "    \"\"\"\n",
    "    for schema, info in schemas.items():\n",
    "        full_schema_name = f\"{catalog_name}.{schema}\"\n",
    "        description = info.get(\"comment\", \"\")\n",
    "        print(f\"Creating schema: {full_schema_name} with description: '{description}'\")\n",
    "\n",
    "        # Drop schema if exists\n",
    "        spark.sql(f\"DROP SCHEMA IF EXISTS {full_schema_name} CASCADE\")\n",
    "\n",
    "        # Create schema with comment\n",
    "        spark.sql(f\"CREATE SCHEMA {full_schema_name} COMMENT '{description}'\")\n",
    "\n",
    "    print(f\"Medallion schemas created in catalog '{catalog_name}' successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "370618bd-0503-4fe8-a525-27e3d20428ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ✅ Run the function using YAML config\n",
    "create_or_update_catalog(\n",
    "    catalog_config['name'],\n",
    "    catalog_config['comment'],\n",
    "    catalog_config['properties']\n",
    ")\n",
    "create_medallion_schemas(catalog_config['name'], medallion_schemas)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
